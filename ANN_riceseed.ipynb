{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_BC-15_basic_features.csv\n",
      "ANN:\n",
      "Accuracy: 91.02%\n",
      "Precision: 91.04%\n",
      "Recall: 91.02%\n",
      "F-measure: 91.02%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Huong_thom-1_basic_features.csv\n",
      "ANN:\n",
      "Accuracy: 94.31%\n",
      "Precision: 94.36%\n",
      "Recall: 94.31%\n",
      "F-measure: 94.31%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Nep-87_basic_features.csv\n",
      "ANN:\n",
      "Accuracy: 97.37%\n",
      "Precision: 97.37%\n",
      "Recall: 97.37%\n",
      "F-measure: 97.37%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Q-5_modify_basic_features.csv\n",
      "ANN:\n",
      "Accuracy: 95.57%\n",
      "Precision: 95.60%\n",
      "Recall: 95.57%\n",
      "F-measure: 95.57%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Thien_uu-8_basic_features.csv\n",
      "ANN:\n",
      "Accuracy: 97.13%\n",
      "Precision: 97.13%\n",
      "Recall: 97.13%\n",
      "F-measure: 97.13%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Xi-23_features.csv\n",
      "ANN:\n",
      "Accuracy: 95.91%\n",
      "Precision: 95.91%\n",
      "Recall: 95.91%\n",
      "F-measure: 95.91%\n",
      "Results have been written to C:\\AIL301m\\result\\ANN\\Basic_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_basic = [\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_BC-15_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Huong_thom-1_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Nep-87_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Q-5_modify_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Thien_uu-8_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Xi-23_features.csv'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_basic:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # Create and fit the ANN classifier\n",
    "    ann = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1000, random_state=42)\n",
    "    ann.fit(X_train, y_train)\n",
    "    y_pred_ann = ann.predict(X_test)\n",
    "    acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "    precision = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"ANN:\")\n",
    "    print(f\"Accuracy: {acc_ann * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_ann * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\ANN\\Basic_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_BC-15_GLCM_features.csv\n",
      "ANN:\n",
      "Accuracy: 72.65%\n",
      "Precision: 73.07%\n",
      "Recall: 72.65%\n",
      "F-measure: 72.45%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Huong_thom-1_GLCM_features.csv\n",
      "ANN:\n",
      "Accuracy: 80.29%\n",
      "Precision: 80.29%\n",
      "Recall: 80.29%\n",
      "F-measure: 80.28%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Nep-87_GLCM_features.csv\n",
      "ANN:\n",
      "Accuracy: 93.78%\n",
      "Precision: 93.81%\n",
      "Recall: 93.78%\n",
      "F-measure: 93.78%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Q-5_modify_GLCM_features.csv\n",
      "ANN:\n",
      "Accuracy: 75.55%\n",
      "Precision: 76.65%\n",
      "Recall: 75.55%\n",
      "F-measure: 75.22%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Thien_uu-8_GLCM_features.csv\n",
      "ANN:\n",
      "Accuracy: 87.92%\n",
      "Precision: 88.00%\n",
      "Recall: 87.92%\n",
      "F-measure: 87.90%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Xi-23_GLCM_features.csv\n",
      "ANN:\n",
      "Accuracy: 78.14%\n",
      "Precision: 78.11%\n",
      "Recall: 78.14%\n",
      "F-measure: 78.01%\n",
      "Results have been written to C:\\AIL301m\\result\\ANN\\GLCM_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_GLCM = [\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_BC-15_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Huong_thom-1_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Nep-87_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Q-5_modify_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Thien_uu-8_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Xi-23_GLCM_features.csv'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_GLCM:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Create and fit the ANN classifier\n",
    "    ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "    ann.fit(X_train, y_train)\n",
    "    y_pred_ann = ann.predict(X_test)\n",
    "    acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "    precision = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"ANN:\")\n",
    "    print(f\"Accuracy: {acc_ann * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_ann * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\ANN\\GLCM_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_BC-15_sift_bow_features.csv\n",
      "ANN:\n",
      "Accuracy: 76.77%\n",
      "Precision: 76.84%\n",
      "Recall: 76.77%\n",
      "F-measure: 76.77%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Huong_thom-1_sift_bow_features.csv\n",
      "ANN:\n",
      "Accuracy: 85.18%\n",
      "Precision: 85.24%\n",
      "Recall: 85.18%\n",
      "F-measure: 85.19%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Nep-87_sift_bow_features.csv\n",
      "ANN:\n",
      "Accuracy: 83.98%\n",
      "Precision: 83.99%\n",
      "Recall: 83.98%\n",
      "F-measure: 83.98%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Q-5_modify_sift_bow_features.csv\n",
      "ANN:\n",
      "Accuracy: 69.92%\n",
      "Precision: 69.96%\n",
      "Recall: 69.92%\n",
      "F-measure: 69.92%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Thien_uu-8_sift_bow_features.csv\n",
      "ANN:\n",
      "Accuracy: 77.79%\n",
      "Precision: 77.87%\n",
      "Recall: 77.79%\n",
      "F-measure: 77.77%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Xi-23_sift_bow_features.csv\n",
      "ANN:\n",
      "Accuracy: 72.66%\n",
      "Precision: 72.76%\n",
      "Recall: 72.66%\n",
      "F-measure: 72.70%\n",
      "Results have been written to C:\\AIL301m\\result\\ANN\\SIFT_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_SIFTandBOW = [\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_BC-15_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Huong_thom-1_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Nep-87_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Q-5_modify_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Thien_uu-8_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Xi-23_sift_bow_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_SIFTandBOW:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data['features'].apply(eval).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Create and fit the ANN classifier\n",
    "    ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "    ann.fit(X_train, y_train)\n",
    "    y_pred_ann = ann.predict(X_test)\n",
    "    acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "    precision = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"ANN:\")\n",
    "    print(f\"Accuracy: {acc_ann * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_ann * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\ANN\\SIFT_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_BC-15_GIST_features.csv\n",
      "ANN:\n",
      "Accuracy: 76.94%\n",
      "Precision: 76.95%\n",
      "Recall: 76.94%\n",
      "F-measure: 76.94%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Huong_thom-1_GIST_features.csv\n",
      "ANN:\n",
      "Accuracy: 89.93%\n",
      "Precision: 89.93%\n",
      "Recall: 89.93%\n",
      "F-measure: 89.92%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Nep-87_GIST_features.csv\n",
      "ANN:\n",
      "Accuracy: 91.36%\n",
      "Precision: 91.37%\n",
      "Recall: 91.36%\n",
      "F-measure: 91.36%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Q-5_modify_GIST_features.csv\n",
      "ANN:\n",
      "Accuracy: 79.68%\n",
      "Precision: 79.81%\n",
      "Recall: 79.68%\n",
      "F-measure: 79.64%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Thien_uu-8_GIST_features.csv\n",
      "ANN:\n",
      "Accuracy: 93.81%\n",
      "Precision: 93.87%\n",
      "Recall: 93.81%\n",
      "F-measure: 93.80%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Xi-23_GIST_features.csv\n",
      "ANN:\n",
      "Accuracy: 85.67%\n",
      "Precision: 85.74%\n",
      "Recall: 85.67%\n",
      "F-measure: 85.69%\n",
      "Results have been written to C:\\AIL301m\\result\\ANN\\GIST_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_GIST = [\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_BC-15_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Huong_thom-1_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Nep-87_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Q-5_modify_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Thien_uu-8_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Xi-23_GIST_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_GIST:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.apply(lambda row: [float(x) for x in row['GistFeature'].split(',')], axis=1).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Create and fit the ANN classifier\n",
    "    ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "    ann.fit(X_train, y_train)\n",
    "    y_pred_ann = ann.predict(X_test)\n",
    "    acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "    precision = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"ANN:\")\n",
    "    print(f\"Accuracy: {acc_ann * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_ann * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\ANN\\GIST_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_BC-15_HOG_features.csv\n",
      "ANN:\n",
      "Accuracy: 86.41%\n",
      "Precision: 86.41%\n",
      "Recall: 86.41%\n",
      "F-measure: 86.40%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Huong_thom-1_HOG_features.csv\n",
      "ANN:\n",
      "Accuracy: 92.41%\n",
      "Precision: 92.41%\n",
      "Recall: 92.41%\n",
      "F-measure: 92.41%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Nep-87_HOG_features.csv\n",
      "ANN:\n",
      "Accuracy: 92.62%\n",
      "Precision: 92.64%\n",
      "Recall: 92.62%\n",
      "F-measure: 92.62%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Q-5_modify_HOG_features.csv\n",
      "ANN:\n",
      "Accuracy: 80.99%\n",
      "Precision: 80.99%\n",
      "Recall: 80.99%\n",
      "F-measure: 80.98%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Thien_uu-8_HOG_features.csv\n",
      "ANN:\n",
      "Accuracy: 95.47%\n",
      "Precision: 95.57%\n",
      "Recall: 95.47%\n",
      "F-measure: 95.46%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Xi-23_HOG_features.csv\n",
      "ANN:\n",
      "Accuracy: 89.47%\n",
      "Precision: 89.48%\n",
      "Recall: 89.47%\n",
      "F-measure: 89.48%\n",
      "Results have been written to C:\\AIL301m\\result\\ANN\\HOG_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_HOG = [\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_BC-15_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Huong_thom-1_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Nep-87_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Q-5_modify_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Thien_uu-8_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Xi-23_HOG_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_HOG:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.apply(lambda row: [float(x) for x in row['HogFeature'].split(',')], axis=1).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Create and fit the ANN classifier\n",
    "    ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "    ann.fit(X_train, y_train)\n",
    "    y_pred_ann = ann.predict(X_test)\n",
    "    acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "    precision = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"ANN:\")\n",
    "    print(f\"Accuracy: {acc_ann * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_ann * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\ANN\\HOG_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_BC-15_LBP_features.csv\n",
      "ANN:\n",
      "Accuracy: 69.93%\n",
      "Precision: 69.94%\n",
      "Recall: 69.93%\n",
      "F-measure: 69.93%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Huong_thom-1_LBP_features.csv\n",
      "ANN:\n",
      "Accuracy: 74.74%\n",
      "Precision: 74.76%\n",
      "Recall: 74.74%\n",
      "F-measure: 74.75%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Nep-87_LBP_features.csv\n",
      "ANN:\n",
      "Accuracy: 87.46%\n",
      "Precision: 87.48%\n",
      "Recall: 87.46%\n",
      "F-measure: 87.46%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Q-5_modify_LBP_features.csv\n",
      "ANN:\n",
      "Accuracy: 73.04%\n",
      "Precision: 73.04%\n",
      "Recall: 73.04%\n",
      "F-measure: 73.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Thien_uu-8_LBP_features.csv\n",
      "ANN:\n",
      "Accuracy: 86.71%\n",
      "Precision: 86.71%\n",
      "Recall: 86.71%\n",
      "F-measure: 86.71%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Xi-23_LBP_features.csv\n",
      "ANN:\n",
      "Accuracy: 72.88%\n",
      "Precision: 72.88%\n",
      "Recall: 72.88%\n",
      "F-measure: 72.88%\n",
      "Results have been written to C:\\AIL301m\\result\\ANN\\LBP_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_LBP = [\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_BC-15_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Huong_thom-1_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Nep-87_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Q-5_modify_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Thien_uu-8_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Xi-23_LBP_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_LBP:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Create and fit the ANN classifier\n",
    "    ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "    ann.fit(X_train, y_train)\n",
    "    y_pred_ann = ann.predict(X_test)\n",
    "    acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "    precision = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"ANN:\")\n",
    "    print(f\"Accuracy: {acc_ann * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_ann * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\ANN\\LBP_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
