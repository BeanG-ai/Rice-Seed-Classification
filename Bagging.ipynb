{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re  # Example import, if needed for other parts of your code\n",
    "import csv  # Example import, if needed for other parts of your code\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from openpyxl import Workbook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dạ thưa cô, đoạn là Bagging Models với 22 Features và  HyperParameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "# Đường dẫn tới các file CSV\n",
    "file_paths_basic = [\n",
    "    r'G:/My Drive/AIL303m/ail2-main/ail2-main/Feature extract/basic/Merged_BC-15_basic_features.csv',\n",
    "    r'G:/My Drive/AIL303m/ail2-main/ail2-main/Feature extract/basic/Merged_Huong_thom-1_basic_features.csv',\n",
    "    r'G:/My Drive/AIL303m/ail2-main/ail2-main/Feature extract/basic/Merged_Nep-87_basic_features.csv',\n",
    "    r'G:/My Drive/AIL303m/ail2-main/ail2-main/Feature extract/basic/Merged_Q-5_modify_basic_features.csv',\n",
    "    r'G:/My Drive/AIL303m/ail2-main/ail2-main/Feature extract/basic/Merged_Thien_uu-8_basic_features.csv',\n",
    "    r'G:/My Drive/AIL303m/ail2-main/ail2-main/Feature extract/basic/Merged_Xi-23_features.csv'\n",
    "]\n",
    "results = []\n",
    "# Suppress specific warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "# Biến để tính tổng độ chính xác\n",
    "total_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "# Hàm chính để huấn luyện và đánh giá mô hình\n",
    "for file_path in file_paths_basic:\n",
    "    name = file_path\n",
    "    match = re.search(r'Merged_(.*?)_features', file_path)\n",
    "    if match:\n",
    "        extracted_string = match.group(1)\n",
    "    # Đọc dữ liệu từ file CSV\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    fold_metrics = {\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F-measure': []\n",
    "    }\n",
    "    # Tiền xử lý dữ liệu\n",
    "    X = dataset.drop(columns=['filename', 'label'], axis=1)\n",
    "    y = dataset['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    k = 5\n",
    "    # Create KFold object\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=25)\n",
    "    # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    # Parameter grids\n",
    "    param_grid_svm = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear','poly']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': range(1, 31),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_features': [22],\n",
    "        'max_depth': [4, 6, 8, 10],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    param_grid_ann = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (150,), (100, 100)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "\n",
    "    param_grid_lr = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    # Define the base models\n",
    "    svm_base = SVC()\n",
    "    knn_base = KNeighborsClassifier()\n",
    "    rf_base = RandomForestClassifier(random_state=42)\n",
    "    ann_base = MLPClassifier(max_iter=1000)\n",
    "    lr_base = LogisticRegression()\n",
    "\n",
    "    # GridSearchCV for each model\n",
    "    gs_svm = GridSearchCV(estimator=svm_base, param_grid=param_grid_svm, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_knn = GridSearchCV(estimator=knn_base, param_grid=param_grid_knn, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_rf = GridSearchCV(estimator=rf_base, param_grid=param_grid_rf, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_ann = GridSearchCV(estimator=ann_base, param_grid=param_grid_ann, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_lr = GridSearchCV(estimator=lr_base, param_grid=param_grid_lr, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "\n",
    "    # Fit GridSearchCV to the data\n",
    "    gs_svm.fit(X_train, y_train)\n",
    "    gs_knn.fit(X_train, y_train)\n",
    "    gs_rf.fit(X_train, y_train)\n",
    "    gs_ann.fit(X_train, y_train)\n",
    "    gs_lr.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimators\n",
    "    best_svm = gs_svm.best_estimator_\n",
    "    best_knn = gs_knn.best_estimator_\n",
    "    best_rf = gs_rf.best_estimator_\n",
    "    best_ann = gs_ann.best_estimator_\n",
    "    best_lr = gs_lr.best_estimator_\n",
    "\n",
    "    print(\"Best SVM Estimator:\", best_svm)\n",
    "    print(\"Best KNN Estimator:\", best_knn)\n",
    "    print(\"Best Random Forest Estimator:\", best_rf)\n",
    "    print(\"Best ANN Estimator:\", best_ann)\n",
    "    print(\"Best Logistic Regression Estimator:\", best_lr)\n",
    "    # Định nghĩa các bộ phân loại Bagging\n",
    "    bagging_svm = BaggingClassifier(best_svm, n_estimators=5, random_state=42, bootstrap=True, max_features=22)\n",
    "    bagging_ann = BaggingClassifier(best_ann, n_estimators=5, random_state=42, bootstrap=True, max_features=22)\n",
    "    bagging_RF = BaggingClassifier(best_rf, n_estimators=5, random_state=42, bootstrap=True, max_features=22)\n",
    "    bagging_knn = BaggingClassifier(best_knn, n_estimators=5, random_state=42, bootstrap=True, max_features=22)\n",
    "    bagging_lr = BaggingClassifier(best_lr,n_estimators=5,random_state=42,bootstrap=True,max_features=22)\n",
    "    # Định nghĩa VotingClassifier với phương pháp hard voting\n",
    "    voting_model = VotingClassifier(estimators=[\n",
    "        ('svm', bagging_svm),\n",
    "        ('rf', bagging_RF),\n",
    "        ('ann', bagging_ann),\n",
    "        ('lr', bagging_lr),\n",
    "        ('knn', bagging_knn)\n",
    "    ], voting='soft')  # Sử dụng soft voting\n",
    "    # Huấn luyện Voting Classifier\n",
    "    voting_model.fit(X_train, y_train)\n",
    "    # Dự đoán trên tập kiểm tra\n",
    "    y_pred = voting_model.predict(X_test)\n",
    "\n",
    "    # Đánh giá độ chính xác của Voting Classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f'Accuracy of Voting Classifier for {extracted_string}: {accuracy:.4f}')\n",
    "    print(f'Precision of Voting Classifier for {extracted_string}: {precision:.4f}')\n",
    "    print(f'Recall of Voting Classifier for {extracted_string}: {recall:.4f}')\n",
    "    print(f'F1-score of Voting Classifier for {extracted_string}: {f1:.4f}')\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    fold_metrics['Accuracy'].append(accuracy)\n",
    "    fold_metrics['Precision'].append(precision)\n",
    "    fold_metrics['Recall'].append(recall)\n",
    "    fold_metrics['F-measure'].append(f1)\n",
    "    # Calculate average metrics for this dataset\n",
    "    avg_metrics = {\n",
    "        'Accuracy': np.mean(fold_metrics['Accuracy']),\n",
    "        'Precision': np.mean(fold_metrics['Precision']),\n",
    "        'Recall': np.mean(fold_metrics['Recall']),\n",
    "        'F-measure': np.mean(fold_metrics['F-measure'])\n",
    "    }\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{avg_metrics['Accuracy'] * 100:.2f}\".replace('.', ',') ,\n",
    "        f\"{avg_metrics['Precision'] * 100:.2f}\".replace('.', ','),\n",
    "        f\"{avg_metrics['Recall'] * 100:.2f}\".replace('.', ',') ,\n",
    "        f\"{avg_metrics['F-measure'] * 100:.2f}\".replace('.', ',')\n",
    "    ])\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    output_file = r\"G:\\My Drive\\AIL303m\\ail2-main\\ail2-main\\BaggingResult(22_Tunning).csv\"\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "        writer.writerows(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36 features Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "# Đường dẫn tới các file CSV\n",
    "file_paths_basic = [\n",
    "    r\"C:\\Users\\Acer\\Documents\\Zalo Received Files\\basic36\\Merged_BC-15_features_v2.csv\",\n",
    "    r\"C:\\Users\\Acer\\Documents\\Zalo Received Files\\basic36\\Merged_Huong_thom-1_features_v2.csv\",\n",
    "    r\"C:\\Users\\Acer\\Documents\\Zalo Received Files\\basic36\\Merged_Nep-87_features_v2.csv\",\n",
    "    r\"C:\\Users\\Acer\\Documents\\Zalo Received Files\\basic36\\Merged_Q-5_modify_features_v2.csv\",\n",
    "    r\"C:\\Users\\Acer\\Documents\\Zalo Received Files\\basic36\\Merged_Thien_uu-8_features_v2.csv\",\n",
    "    r\"C:\\Users\\Acer\\Documents\\Zalo Received Files\\basic36\\Merged_Xi-23_features_v2.csv\",\n",
    "]\n",
    "results = []\n",
    "# Suppress specific warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "# Biến để tính tổng độ chính xác\n",
    "total_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "# Hàm chính để huấn luyện và đánh giá mô hình\n",
    "for file_path in file_paths_basic:\n",
    "    name = file_path\n",
    "    match = re.search(r'Merged_(.*?)_features', file_path)\n",
    "    if match:\n",
    "        extracted_string = match.group(1)\n",
    "    # Đọc dữ liệu từ file CSV\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    fold_metrics = {\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F-measure': []\n",
    "    }\n",
    "    # Tiền xử lý dữ liệu\n",
    "    X = dataset.drop(columns=['filename', 'label'], axis=1)\n",
    "    y = dataset['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    k = 5\n",
    "    # Create KFold object\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=25)\n",
    "    # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    # Parameter grids\n",
    "    param_grid_svm = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear','poly']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': range(1, 31),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_features': [7,8], \n",
    "        'max_depth': [4, 6, 8, 10],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    param_grid_ann = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (150,), (100, 100)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "\n",
    "    param_grid_lr = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    # Define the base models\n",
    "    svm_base = SVC()\n",
    "    knn_base = KNeighborsClassifier()\n",
    "    rf_base = RandomForestClassifier(random_state=42)\n",
    "    ann_base = MLPClassifier(max_iter=1000)\n",
    "    lr_base = LogisticRegression()\n",
    "\n",
    "    # GridSearchCV for each model\n",
    "    gs_svm = GridSearchCV(estimator=svm_base, param_grid=param_grid_svm, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_knn = GridSearchCV(estimator=knn_base, param_grid=param_grid_knn, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_rf = GridSearchCV(estimator=rf_base, param_grid=param_grid_rf, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_ann = GridSearchCV(estimator=ann_base, param_grid=param_grid_ann, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_lr = GridSearchCV(estimator=lr_base, param_grid=param_grid_lr, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "\n",
    "    # Get the best estimators\n",
    "    best_svm = gs_svm.best_estimator_\n",
    "    best_knn = gs_knn.best_estimator_\n",
    "    best_rf = gs_rf.best_estimator_\n",
    "    best_ann = gs_ann.best_estimator_\n",
    "    best_lr = gs_lr.best_estimator_\n",
    "\n",
    "    print(\"Best SVM Estimator:\", best_svm)\n",
    "    print(\"Best KNN Estimator:\", best_knn)\n",
    "    print(\"Best Random Forest Estimator:\", best_rf)\n",
    "    print(\"Best ANN Estimator:\", best_ann)\n",
    "    print(\"Best Logistic Regression Estimator:\", best_lr)\n",
    "    # Định nghĩa các bộ phân loại Bagging\n",
    "    bagging_svm = BaggingClassifier(best_svm, n_estimators=i, random_state=42, bootstrap=True, max_features=52)\n",
    "    bagging_ann = BaggingClassifier(best_ann, n_estimators=i, random_state=42, bootstrap=True, max_features=52)\n",
    "    bagging_RF = BaggingClassifier(best_rf, n_estimators=i, random_state=42, bootstrap=True, max_features=52)\n",
    "    bagging_knn = BaggingClassifier(best_knn, n_estimators=i, random_state=42, bootstrap=True, max_features=52)\n",
    "    bagging_lr = BaggingClassifier(best_lr,n_estimators=i,random_state=42,bootstrap=True,max_features=52)\n",
    "    # Định nghĩa VotingClassifier với phương pháp hard voting\n",
    "    voting_model = VotingClassifier(estimators=[\n",
    "        ('svm', bagging_svm),\n",
    "        ('rf', bagging_RF),\n",
    "        ('ann', bagging_ann),\n",
    "        ('lr', bagging_lr),\n",
    "        ('knn', bagging_knn)\n",
    "    ], voting='soft')  # Sử dụng soft voting\n",
    "    # Huấn luyện Voting Classifier\n",
    "    voting_model.fit(X_train, y_train).to(device)\n",
    "\n",
    "    # Dự đoán trên tập kiểm tra\n",
    "    y_pred = voting_model.predict(X_test)\n",
    "\n",
    "    # Đánh giá độ chính xác của Voting Classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f'n_estimators= {i}')\n",
    "    print(f'Accuracy of Voting Classifier for {extracted_string}: {accuracy:.4f}')\n",
    "    print(f'Precision of Voting Classifier for {extracted_string}: {precision:.4f}')\n",
    "    print(f'Recall of Voting Classifier for {extracted_string}: {recall:.4f}')\n",
    "    print(f'F1-score of Voting Classifier for {extracted_string}: {f1:.4f}')\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    fold_metrics['Accuracy'].append(accuracy)\n",
    "    fold_metrics['Precision'].append(precision)\n",
    "    fold_metrics['Recall'].append(recall)\n",
    "    fold_metrics['F-measure'].append(f1)\n",
    "    # Calculate average metrics for this dataset\n",
    "    avg_metrics = {\n",
    "        'Accuracy': np.mean(fold_metrics['Accuracy']),\n",
    "        'Precision': np.mean(fold_metrics['Precision']),\n",
    "        'Recall': np.mean(fold_metrics['Recall']),\n",
    "        'F-measure': np.mean(fold_metrics['F-measure'])\n",
    "    }\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{avg_metrics['Accuracy'] * 100:.2f}\".replace('.', ','),\n",
    "        f\"{avg_metrics['Precision'] * 100:.2f}\".replace('.', ','),\n",
    "        f\"{avg_metrics['Recall'] * 100:.2f}\".replace('.', ','),\n",
    "        f\"{avg_metrics['F-measure'] * 100:.2f}\".replace('.', ',')\n",
    "    ])\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    output_file = rf\"G:\\My Drive\\AIL303m\\ail2-main\\BaggingNewResult(36_Tunning) .xlsx\"\n",
    "    # Create a workbook and select the active worksheet\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    # Write the header\n",
    "    ws.append(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "\n",
    "    # Write the results\n",
    "    for result in results:\n",
    "        ws.append(result)\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dạ thưa cô, đây là Bagging Models dùng Voting với 52 features và có Hypterparameter Tunning ạ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "# Đường dẫn tới các file CSV\n",
    "file_paths_basic = [\n",
    "    r\"G:\\My Drive\\AIL303m\\ail2-main\\basicv3\\Merged_BC-15_features_v3.csv\",\n",
    "    r\"G:\\My Drive\\AIL303m\\ail2-main\\basicv3\\Merged_Huong_thom-1_features_v3.csv\",\n",
    "    r\"G:\\My Drive\\AIL303m\\ail2-main\\basicv3\\Merged_Nep-87_features_v3.csv\",\n",
    "    r\"G:\\My Drive\\AIL303m\\ail2-main\\basicv3\\Merged_Q-5_modify_features_v3.csv\",\n",
    "    r\"G:\\My Drive\\AIL303m\\ail2-main\\basicv3\\Merged_Thien_uu-8_features_v3.csv\",\n",
    "    r\"G:\\My Drive\\AIL303m\\ail2-main\\basicv3\\Merged_Xi-23_features_v3.csv\",\n",
    "]\n",
    "results = []\n",
    "# Suppress specific warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "# Biến để tính tổng độ chính xác\n",
    "total_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "# Hàm chính để huấn luyện và đánh giá mô hình\n",
    "for file_path in file_paths_basic:\n",
    "    name = file_path\n",
    "    match = re.search(r'Merged_(.*?)_features', file_path)\n",
    "    if match:\n",
    "        extracted_string = match.group(1)\n",
    "    # Đọc dữ liệu từ file CSV\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    fold_metrics = {\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F-measure': []\n",
    "    }\n",
    "    # Tiền xử lý dữ liệu\n",
    "    X = dataset.drop(columns=['filename', 'label'], axis=1)\n",
    "    y = dataset['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    k = 5\n",
    "    # Create KFold object\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=25)\n",
    "    # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    # Parameter grids\n",
    "    param_grid_svm = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear','poly']\n",
    "    }\n",
    "\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': range(1, 31),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }\n",
    "\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_features': [7,8], \n",
    "        'max_depth': [4, 6, 8, 10],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    param_grid_ann = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (150,), (100, 100)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "\n",
    "    param_grid_lr = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'penalty': ['l2', 'l1'],\n",
    "        'max_iter': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    # Define the base models\n",
    "    svm_base = SVC()\n",
    "    knn_base = KNeighborsClassifier()\n",
    "    rf_base = RandomForestClassifier(random_state=42)\n",
    "    ann_base = MLPClassifier(max_iter=1000)\n",
    "    lr_base = LogisticRegression()\n",
    "\n",
    "    # GridSearchCV for each model\n",
    "    gs_svm = GridSearchCV(estimator=svm_base, param_grid=param_grid_svm, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_knn = GridSearchCV(estimator=knn_base, param_grid=param_grid_knn, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_rf = GridSearchCV(estimator=rf_base, param_grid=param_grid_rf, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_ann = GridSearchCV(estimator=ann_base, param_grid=param_grid_ann, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "    gs_lr = GridSearchCV(estimator=lr_base, param_grid=param_grid_lr, cv=kf, verbose=1, scoring='accuracy',error_score='raise')\n",
    "\n",
    "    # Fit GridSearchCV to the data\n",
    "    gs_svm.fit(X_train, y_train)\n",
    "    gs_knn.fit(X_train, y_train)\n",
    "    gs_rf.fit(X_train, y_train)\n",
    "    gs_ann.fit(X_train, y_train)\n",
    "    gs_lr.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimators\n",
    "    best_svm = gs_svm.best_estimator_\n",
    "    best_knn = gs_knn.best_estimator_\n",
    "    best_rf = gs_rf.best_estimator_\n",
    "    best_ann = gs_ann.best_estimator_\n",
    "    best_lr = gs_lr.best_estimator_\n",
    "\n",
    "    print(\"Best SVM Estimator:\", best_svm)\n",
    "    print(\"Best KNN Estimator:\", best_knn)\n",
    "    print(\"Best Random Forest Estimator:\", best_rf)\n",
    "    print(\"Best ANN Estimator:\", best_ann)\n",
    "    print(\"Best Logistic Regression Estimator:\", best_lr)\n",
    "    # Định nghĩa các bộ phân loại Bagging\n",
    "    bagging_svm = BaggingClassifier(best_svm, n_estimators=5, random_state=42, bootstrap=True, max_features=36)\n",
    "    bagging_ann = BaggingClassifier(best_ann, n_estimators=5, random_state=42, bootstrap=True, max_features=36)\n",
    "    bagging_RF = BaggingClassifier(best_rf, n_estimators=5, random_state=42, bootstrap=True, max_features=36)\n",
    "    bagging_knn = BaggingClassifier(best_knn, n_estimators=5, random_state=42, bootstrap=True, max_features=36)\n",
    "    bagging_lr = BaggingClassifier(best_lr,n_estimators=5,random_state=42,bootstrap=True,max_features=36)\n",
    "    # Định nghĩa VotingClassifier với phương pháp hard voting\n",
    "    voting_model = VotingClassifier(estimators=[\n",
    "        ('svm', bagging_svm),\n",
    "        ('rf', bagging_RF),\n",
    "        ('ann', bagging_ann),\n",
    "        ('lr', bagging_lr),\n",
    "        ('knn', bagging_knn)\n",
    "    ], voting='soft')  # Sử dụng soft voting\n",
    "    # Huấn luyện Voting Classifier\n",
    "    voting_model.fit(X_train, y_train)\n",
    "    # Dự đoán trên tập kiểm tra\n",
    "    y_pred = voting_model.predict(X_test)\n",
    "\n",
    "    # Đánh giá độ chính xác của Voting Classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f'Accuracy of Voting Classifier for {extracted_string}: {accuracy:.4f}')\n",
    "    print(f'Precision of Voting Classifier for {extracted_string}: {precision:.4f}')\n",
    "    print(f'Recall of Voting Classifier for {extracted_string}: {recall:.4f}')\n",
    "    print(f'F1-score of Voting Classifier for {extracted_string}: {f1:.4f}')\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    fold_metrics['Accuracy'].append(accuracy)\n",
    "    fold_metrics['Precision'].append(precision)\n",
    "    fold_metrics['Recall'].append(recall)\n",
    "    fold_metrics['F-measure'].append(f1)\n",
    "    # Calculate average metrics for this dataset\n",
    "    avg_metrics = {\n",
    "        'Accuracy': np.mean(fold_metrics['Accuracy']),\n",
    "        'Precision': np.mean(fold_metrics['Precision']),\n",
    "        'Recall': np.mean(fold_metrics['Recall']),\n",
    "        'F-measure': np.mean(fold_metrics['F-measure'])\n",
    "    }\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{avg_metrics['Accuracy'] * 100:.2f}\".replace('.', ','),\n",
    "        f\"{avg_metrics['Precision'] * 100:.2f}\".replace('.', ','),\n",
    "        f\"{avg_metrics['Recall'] * 100:.2f}\".replace('.', ','),\n",
    "        f\"{avg_metrics['F-measure'] * 100:.2f}\".replace('.', ','),\n",
    "    ])\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    output_file = r\"G:\\My Drive\\AIL303m\\ail2-main\\BaggingNewResult(52_Tuning).xlsx\"\n",
    "    # Create a workbook and select the active worksheet\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    # Write the header\n",
    "    ws.append(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure'])\n",
    "\n",
    "    # Write the results\n",
    "    for result in results:\n",
    "        ws.append(result)\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
