{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_BC-15_basic_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 89.21%\n",
      "Precision: 88.65%\n",
      "Recall: 91.02%\n",
      "F-measure: 89.82%\n",
      "OOB Score: 88.92%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Huong_thom-1_basic_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 91.53%\n",
      "Precision: 91.38%\n",
      "Recall: 91.91%\n",
      "F-measure: 91.64%\n",
      "OOB Score: 91.40%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Nep-87_basic_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 97.37%\n",
      "Precision: 98.01%\n",
      "Recall: 96.51%\n",
      "F-measure: 97.26%\n",
      "OOB Score: 97.35%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Q-5_modify_basic_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 94.57%\n",
      "Precision: 93.52%\n",
      "Recall: 95.77%\n",
      "F-measure: 94.63%\n",
      "OOB Score: 93.85%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Thien_uu-8_basic_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 94.41%\n",
      "Precision: 94.71%\n",
      "Recall: 94.43%\n",
      "F-measure: 94.57%\n",
      "OOB Score: 95.91%\n",
      "File: C:\\AIL301m\\Feature extract\\basic\\Merged_Xi-23_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 92.69%\n",
      "Precision: 93.36%\n",
      "Recall: 92.85%\n",
      "F-measure: 93.10%\n",
      "OOB Score: 92.69%\n",
      "Results have been written to C:\\AIL301m\\result\\RF\\Basic_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_paths_basic = [\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_BC-15_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Huong_thom-1_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Nep-87_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Q-5_modify_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Thien_uu-8_basic_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\basic\\Merged_Xi-23_features.csv'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_basic:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform the custom split: 67% training, 33% testing\n",
    "    n_samples = len(y)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(0.67 * n_samples)\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_indices], X_scaled[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # Create and fit the Random Forest classifier with specified parameters\n",
    "    rf = RandomForestClassifier(n_estimators=500, max_features=22, random_state=42, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "    oob_score = rf.oob_score_\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Random Forest:\")\n",
    "    print(f\"Accuracy: {acc_rf * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"OOB Score: {oob_score * 100:.2f}%\")\n",
    "    \n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_rf * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{oob_score * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\RF\\Basic_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'OOB Score'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_BC-15_GLCM_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 71.66%\n",
      "Precision: 69.27%\n",
      "Recall: 74.23%\n",
      "F-measure: 71.66%\n",
      "OOB Score: 68.45%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Huong_thom-1_GLCM_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 78.98%\n",
      "Precision: 77.54%\n",
      "Recall: 83.26%\n",
      "F-measure: 80.30%\n",
      "OOB Score: 78.13%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Nep-87_GLCM_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 89.99%\n",
      "Precision: 89.17%\n",
      "Recall: 90.52%\n",
      "F-measure: 89.84%\n",
      "OOB Score: 90.75%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Q-5_modify_GLCM_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 73.24%\n",
      "Precision: 72.71%\n",
      "Recall: 75.60%\n",
      "F-measure: 74.12%\n",
      "OOB Score: 72.12%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Thien_uu-8_GLCM_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 85.05%\n",
      "Precision: 84.32%\n",
      "Recall: 86.10%\n",
      "F-measure: 85.20%\n",
      "OOB Score: 84.67%\n",
      "File: C:\\AIL301m\\Feature extract\\GLCM\\Merged_Xi-23_GLCM_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 74.34%\n",
      "Precision: 75.00%\n",
      "Recall: 77.78%\n",
      "F-measure: 76.36%\n",
      "OOB Score: 75.66%\n",
      "Results have been written to C:\\AIL301m\\result\\RF\\GLCM_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_GLCM = [\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_BC-15_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Huong_thom-1_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Nep-87_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Q-5_modify_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Thien_uu-8_GLCM_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GLCM\\Merged_Xi-23_GLCM_features.csv'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_GLCM:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform the custom split: 67% training, 33% testing\n",
    "    n_samples = len(y)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(0.67 * n_samples)\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_indices], X_scaled[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # Create and fit the Random Forest classifier with specified parameters\n",
    "    rf = RandomForestClassifier(n_estimators=500, max_features=5, random_state=42, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "    oob_score = rf.oob_score_\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Random Forest:\")\n",
    "    print(f\"Accuracy: {acc_rf * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"OOB Score: {oob_score * 100:.2f}%\")\n",
    "    \n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_rf * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{oob_score * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\RF\\GLCM_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'OOB Score'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_BC-15_sift_bow_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 79.24%\n",
      "Precision: 78.99%\n",
      "Recall: 79.77%\n",
      "F-measure: 79.38%\n",
      "OOB Score: 78.52%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Huong_thom-1_sift_bow_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 85.18%\n",
      "Precision: 85.11%\n",
      "Recall: 85.23%\n",
      "F-measure: 85.17%\n",
      "OOB Score: 86.26%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Nep-87_sift_bow_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 83.46%\n",
      "Precision: 82.08%\n",
      "Recall: 84.73%\n",
      "F-measure: 83.39%\n",
      "OOB Score: 84.93%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Q-5_modify_sift_bow_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 70.42%\n",
      "Precision: 72.02%\n",
      "Recall: 70.35%\n",
      "F-measure: 71.18%\n",
      "OOB Score: 71.03%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Thien_uu-8_sift_bow_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 77.19%\n",
      "Precision: 77.19%\n",
      "Recall: 78.34%\n",
      "F-measure: 77.76%\n",
      "OOB Score: 78.72%\n",
      "File: C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Xi-23_sift_bow_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 74.63%\n",
      "Precision: 73.70%\n",
      "Recall: 81.67%\n",
      "F-measure: 77.48%\n",
      "OOB Score: 72.31%\n",
      "Results have been written to C:\\AIL301m\\result\\RF\\SIFT_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_SIFTandBOW = [\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_BC-15_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Huong_thom-1_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Nep-87_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Q-5_modify_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Thien_uu-8_sift_bow_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Xi-23_sift_bow_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_SIFTandBOW:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data['features'].apply(eval).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform the custom split: 67% training, 33% testing\n",
    "    n_samples = len(y)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(0.67 * n_samples)\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_indices], X_scaled[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # Create and fit the Random Forest classifier with specified parameters\n",
    "    rf = RandomForestClassifier(n_estimators=500, max_features=18, random_state=42, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "    oob_score = rf.oob_score_\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Random Forest:\")\n",
    "    print(f\"Accuracy: {acc_rf * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"OOB Score: {oob_score * 100:.2f}%\")\n",
    "    \n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_rf * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{oob_score * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\RF\\SIFT_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'OOB Score'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_BC-15_GIST_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 74.46%\n",
      "Precision: 74.03%\n",
      "Recall: 75.49%\n",
      "F-measure: 74.76%\n",
      "OOB Score: 73.16%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Huong_thom-1_GIST_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 84.74%\n",
      "Precision: 86.63%\n",
      "Recall: 83.05%\n",
      "F-measure: 84.80%\n",
      "OOB Score: 84.35%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Nep-87_GIST_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 88.41%\n",
      "Precision: 86.01%\n",
      "Recall: 90.87%\n",
      "F-measure: 88.37%\n",
      "OOB Score: 86.75%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Q-5_modify_GIST_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 76.56%\n",
      "Precision: 73.71%\n",
      "Recall: 78.56%\n",
      "F-measure: 76.05%\n",
      "OOB Score: 76.39%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Thien_uu-8_GIST_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 91.24%\n",
      "Precision: 93.65%\n",
      "Recall: 88.59%\n",
      "F-measure: 91.05%\n",
      "OOB Score: 90.25%\n",
      "File: C:\\AIL301m\\Feature extract\\GIST\\Merged_Xi-23_GIST_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 76.75%\n",
      "Precision: 77.27%\n",
      "Recall: 83.09%\n",
      "F-measure: 80.08%\n",
      "OOB Score: 76.88%\n",
      "Results have been written to C:\\AIL301m\\result\\RF\\GIST_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_GIST = [\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_BC-15_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Huong_thom-1_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Nep-87_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Q-5_modify_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Thien_uu-8_GIST_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\GIST\\Merged_Xi-23_GIST_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_GIST:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.apply(lambda row: [float(x) for x in row['GistFeature'].split(',')], axis=1).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform the custom split: 67% training, 33% testing\n",
    "    n_samples = len(y)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(0.67 * n_samples)\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_indices], X_scaled[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # Create and fit the Random Forest classifier with specified parameters\n",
    "    rf = RandomForestClassifier(n_estimators=500, max_features=23, random_state=42, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "    oob_score = rf.oob_score_\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Random Forest:\")\n",
    "    print(f\"Accuracy: {acc_rf * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"OOB Score: {oob_score * 100:.2f}%\")\n",
    "    \n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_rf * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{oob_score * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\RF\\GIST_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'OOB Score'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_BC-15_HOG_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 85.50%\n",
      "Precision: 82.72%\n",
      "Recall: 89.33%\n",
      "F-measure: 85.90%\n",
      "OOB Score: 84.73%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Huong_thom-1_HOG_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 87.59%\n",
      "Precision: 85.61%\n",
      "Recall: 89.93%\n",
      "F-measure: 87.72%\n",
      "OOB Score: 88.49%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Nep-87_HOG_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 88.20%\n",
      "Precision: 87.77%\n",
      "Recall: 87.77%\n",
      "F-measure: 87.77%\n",
      "OOB Score: 87.79%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Q-5_modify_HOG_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 76.66%\n",
      "Precision: 75.14%\n",
      "Recall: 81.34%\n",
      "F-measure: 78.11%\n",
      "OOB Score: 76.84%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Thien_uu-8_HOG_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 94.26%\n",
      "Precision: 93.43%\n",
      "Recall: 95.61%\n",
      "F-measure: 94.51%\n",
      "OOB Score: 92.34%\n",
      "File: C:\\AIL301m\\Feature extract\\HOG\\Merged_Xi-23_HOG_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 84.36%\n",
      "Precision: 84.81%\n",
      "Recall: 86.64%\n",
      "F-measure: 85.71%\n",
      "OOB Score: 82.39%\n",
      "Results have been written to C:\\AIL301m\\result\\RF\\HOG_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_HOG = [\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_BC-15_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Huong_thom-1_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Nep-87_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Q-5_modify_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Thien_uu-8_HOG_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\HOG\\Merged_Xi-23_HOG_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_HOG:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.apply(lambda row: [float(x) for x in row['HogFeature'].split(',')], axis=1).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform the custom split: 67% training, 33% testing\n",
    "    n_samples = len(y)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(0.67 * n_samples)\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_indices], X_scaled[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # Create and fit the Random Forest classifier with specified parameters\n",
    "    rf = RandomForestClassifier(n_estimators=500, max_features=23, random_state=42, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "    oob_score = rf.oob_score_\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Random Forest:\")\n",
    "    print(f\"Accuracy: {acc_rf * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"OOB Score: {oob_score * 100:.2f}%\")\n",
    "    \n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_rf * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{oob_score * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\RF\\HOG_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'OOB Score'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_BC-15_LBP_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 67.46%\n",
      "Precision: 66.06%\n",
      "Recall: 67.97%\n",
      "F-measure: 67.00%\n",
      "OOB Score: 67.72%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Huong_thom-1_LBP_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 72.92%\n",
      "Precision: 74.74%\n",
      "Recall: 71.45%\n",
      "F-measure: 73.06%\n",
      "OOB Score: 71.58%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Nep-87_LBP_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 87.67%\n",
      "Precision: 89.14%\n",
      "Recall: 85.10%\n",
      "F-measure: 87.07%\n",
      "OOB Score: 86.07%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Q-5_modify_LBP_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 67.20%\n",
      "Precision: 65.83%\n",
      "Recall: 69.86%\n",
      "F-measure: 67.79%\n",
      "OOB Score: 68.65%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Thien_uu-8_LBP_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 85.95%\n",
      "Precision: 87.50%\n",
      "Recall: 83.49%\n",
      "F-measure: 85.45%\n",
      "OOB Score: 85.19%\n",
      "File: C:\\AIL301m\\Feature extract\\LBP\\Merged_Xi-23_LBP_features.csv\n",
      "Random Forest:\n",
      "Accuracy: 72.81%\n",
      "Precision: 74.09%\n",
      "Recall: 78.01%\n",
      "F-measure: 76.00%\n",
      "OOB Score: 70.76%\n",
      "Results have been written to C:\\AIL301m\\result\\RF\\LBP_results.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths_LBP = [\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_BC-15_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Huong_thom-1_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Nep-87_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Q-5_modify_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Thien_uu-8_LBP_features.csv',\n",
    "    r'C:\\AIL301m\\Feature extract\\LBP\\Merged_Xi-23_LBP_features.csv'\n",
    "]\n",
    "results = []\n",
    "\n",
    "for file_path in file_paths_LBP:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform the custom split: 67% training, 33% testing\n",
    "    n_samples = len(y)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_size = int(0.67 * n_samples)\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_indices], X_scaled[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # Create and fit the Random Forest classifier with specified parameters\n",
    "    rf = RandomForestClassifier(n_estimators=500, max_features=10, random_state=42, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision = precision_score(y_test, y_pred_rf)\n",
    "    recall = recall_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "    oob_score = rf.oob_score_\n",
    "    \n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Random Forest:\")\n",
    "    print(f\"Accuracy: {acc_rf * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"OOB Score: {oob_score * 100:.2f}%\")\n",
    "    \n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc_rf * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{oob_score * 100:.2f}\".replace('.', ',') + '%'\n",
    "    ])\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'C:\\AIL301m\\result\\RF\\LBP_results.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'OOB Score'])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
