{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature Extraction (SIFT)\n",
    "def extract_sift_features(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Vocabulary Building (KMeans Clustering)\n",
    "def build_vocabulary(descriptors, vocabulary_size):\n",
    "    kmeans = KMeans(n_clusters=vocabulary_size)\n",
    "    kmeans.fit(descriptors)\n",
    "    vocabulary = kmeans.cluster_centers_\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Quantization\n",
    "def quantize_features(descriptors, vocabulary):\n",
    "    num_features = descriptors.shape[0]\n",
    "    feature_vector = np.zeros((1, len(vocabulary)), dtype=np.float32)\n",
    "    for i in range(num_features):\n",
    "        feature = descriptors[i]\n",
    "        feature = feature.reshape(1, -1)\n",
    "        distances = np.linalg.norm(feature - vocabulary, axis=1)\n",
    "        nearest_word_index = np.argmin(distances)\n",
    "        feature_vector[0, nearest_word_index] += 1\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Histogram Representation\n",
    "def compute_histogram(image_path, vocabulary):\n",
    "    keypoints, descriptors = extract_sift_features(image_path)\n",
    "    histogram = quantize_features(descriptors, vocabulary)\n",
    "    return histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Combine SIFT descriptors with BoW histogram\n",
    "def extract_combined_features(image_path, vocabulary):\n",
    "    keypoints, descriptors = extract_sift_features(image_path)\n",
    "    bow_histogram = compute_histogram(image_path, vocabulary)\n",
    "    combined_features = np.hstack((descriptors.flatten(), bow_histogram.flatten()))\n",
    "    return combined_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_in_folder(folder_path, output_csv, vocabulary_size):\n",
    "    results = []\n",
    "\n",
    "    # Determine label based on folder name pattern\n",
    "    label = 0 if \"Negative_\" in os.path.basename(folder_path) else 1\n",
    "\n",
    "    # Extract SIFT features and build vocabulary\n",
    "    descriptors_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            keypoints, descriptors = extract_sift_features(file_path)\n",
    "            if descriptors is not None:\n",
    "                descriptors_list.append(descriptors)\n",
    "    descriptors_array = np.vstack(descriptors_list)\n",
    "    vocabulary = build_vocabulary(descriptors_array, vocabulary_size)\n",
    "\n",
    "    # Compute combined features for each image\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            combined_features = extract_combined_features(file_path, vocabulary)\n",
    "            results.append({\n",
    "                'filename': filename,\n",
    "                'features': combined_features,\n",
    "                'label': label\n",
    "            })\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        fieldnames = ['filename', 'features', 'label']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for result in results:\n",
    "            writer.writerow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Process Multiple Folders\n",
    "def process_multiple_folders(base_folder, vocabulary_size):\n",
    "    for folder_name in os.listdir(base_folder):\n",
    "        folder_path = os.path.join(base_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            output_csv = f'SIFTandBOW/{folder_name}_sift_bow_features.csv'\n",
    "            process_images_in_folder(folder_path, output_csv, vocabulary_size)\n",
    "            print(f\"SIFT and BoW features have been calculated for images in {folder_path} and written to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT and BoW features have been calculated for images in Rice_photos/BC-15\\BC-15 and written to SIFTandBOW/BC-15_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/BC-15\\Negative_BC-15 and written to SIFTandBOW/Negative_BC-15_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Huongthom\\Huong_thom-1 and written to SIFTandBOW/Huong_thom-1_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Huongthom\\Negative_Huong_thom-1 and written to SIFTandBOW/Negative_Huong_thom-1_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Nep87\\Negative_Nep-87 and written to SIFTandBOW/Negative_Nep-87_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Nep87\\Nep-87 and written to SIFTandBOW/Nep-87_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Q5\\Negative_Q-5_modify and written to SIFTandBOW/Negative_Q-5_modify_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Q5\\Q-5_modify and written to SIFTandBOW/Q-5_modify_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Thien_uu\\Negative_Thien_uu-8 and written to SIFTandBOW/Negative_Thien_uu-8_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Thien_uu\\Thien_uu-8 and written to SIFTandBOW/Thien_uu-8_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Xi23\\Negative_Xi-23 and written to SIFTandBOW/Negative_Xi-23_sift_bow_features.csv\n",
      "SIFT and BoW features have been calculated for images in Rice_photos/Xi23\\Xi-23 and written to SIFTandBOW/Xi-23_sift_bow_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    folder = ['Rice_photos/BC-15', 'Rice_photos/Huongthom', 'Rice_photos/Nep87', 'Rice_photos/Q5', 'Rice_photos/Thien_uu', 'Rice_photos/Xi23']\n",
    "    vocabulary_size = 100\n",
    "    for i in range(len(folder)):\n",
    "        base_folder = folder[i]\n",
    "        process_multiple_folders(base_folder,vocabulary_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
