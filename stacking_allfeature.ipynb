{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import csv\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_GLCM = [\n",
    "    r'D:\\AIL301m\\Feature extract\\GLCM\\Merged_BC-15_GLCM_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GLCM\\Merged_Huong_thom-1_GLCM_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GLCM\\Merged_Nep-87_GLCM_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GLCM\\Merged_Q-5_modify_GLCM_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GLCM\\Merged_Thien_uu-8_GLCM_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GLCM\\Merged_Xi-23_GLCM_features.csv'\n",
    "]\n",
    "results = []\n",
    "accuracies = []\n",
    "runtimes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\AIL301m\\Feature extract\\GLCM\\Merged_BC-15_GLCM_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 72.16%\n",
      "Precision: 72.47%\n",
      "Recall: 72.16%\n",
      "F-measure: 71.99%\n",
      "Runtime: 76.98 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GLCM\\Merged_Huong_thom-1_GLCM_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 79.71%\n",
      "Precision: 79.70%\n",
      "Recall: 79.71%\n",
      "F-measure: 79.70%\n",
      "Runtime: 81.79 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GLCM\\Merged_Nep-87_GLCM_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 93.89%\n",
      "Precision: 93.90%\n",
      "Recall: 93.89%\n",
      "F-measure: 93.89%\n",
      "Runtime: 40.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\AIL301m\\Feature extract\\GLCM\\Merged_Q-5_modify_GLCM_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 75.15%\n",
      "Precision: 75.41%\n",
      "Recall: 75.15%\n",
      "F-measure: 75.05%\n",
      "Runtime: 69.72 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GLCM\\Merged_Thien_uu-8_GLCM_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 87.46%\n",
      "Precision: 87.50%\n",
      "Recall: 87.46%\n",
      "F-measure: 87.46%\n",
      "Runtime: 36.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\AIL301m\\Feature extract\\GLCM\\Merged_Xi-23_GLCM_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 77.49%\n",
      "Precision: 77.42%\n",
      "Recall: 77.49%\n",
      "F-measure: 77.40%\n",
      "Runtime: 94.44 seconds\n",
      "Overall Average Accuracy: 80.98%\n",
      "Results have been written to D:\\AIL301m\\time\\Stacking\\GLCM.csv\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths_GLCM:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "    # Define base models with specific parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=4, weights='distance',metric='euclidean')\n",
    "    ann = MLPClassifier(activation='tanh',alpha=0.05, hidden_layer_sizes=(50,) ,max_iter=1000, random_state=42)\n",
    "    svm = SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=1200, max_features=3,criterion='entropy',max_depth=10, random_state=42)\n",
    "    \n",
    "    # Define meta-learner\n",
    "    meta_learner = LogisticRegression(C=100, solver='liblinear',random_state=42)\n",
    "    \n",
    "    # Create the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('knn', knn), ('ann', ann), ('svm', svm), ('rf', rf)],\n",
    "        final_estimator=meta_learner,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier\n",
    "    start_time = time.time()\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_pred = stacking_classifier.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    runtimes.append(runtime)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Stacking Model (KNN + ANN + SVM + RF):\")\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"Runtime: {runtime:.2f} seconds\")  # Output runtime\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{runtime:.2f} seconds\"\n",
    "    ])\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'D:\\AIL301m\\time\\Stacking\\GLCM.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'Runtime (s)'])\n",
    "    writer.writerows(results)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Average Accuracy: {average_accuracy * 100:.2f}%\") \n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_SIFTandBOW = [\n",
    "    r'D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_BC-15_sift_bow_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Huong_thom-1_sift_bow_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Nep-87_sift_bow_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Q-5_modify_sift_bow_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Thien_uu-8_sift_bow_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Xi-23_sift_bow_features.csv'\n",
    "]\n",
    "results = []\n",
    "accuracies = []\n",
    "runtimes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_BC-15_sift_bow_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 78.42%\n",
      "Precision: 78.59%\n",
      "Recall: 78.42%\n",
      "F-measure: 78.41%\n",
      "Runtime: 56.38 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Huong_thom-1_sift_bow_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 85.99%\n",
      "Precision: 86.06%\n",
      "Recall: 85.99%\n",
      "F-measure: 85.99%\n",
      "Runtime: 63.96 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Nep-87_sift_bow_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 85.56%\n",
      "Precision: 85.59%\n",
      "Recall: 85.56%\n",
      "F-measure: 85.56%\n",
      "Runtime: 41.49 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Q-5_modify_sift_bow_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 70.82%\n",
      "Precision: 70.96%\n",
      "Recall: 70.82%\n",
      "F-measure: 70.81%\n",
      "Runtime: 65.29 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Thien_uu-8_sift_bow_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 79.61%\n",
      "Precision: 80.08%\n",
      "Recall: 79.61%\n",
      "F-measure: 79.50%\n",
      "Runtime: 38.28 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\SIFTandBOW\\Merged_Xi-23_sift_bow_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 74.71%\n",
      "Precision: 74.79%\n",
      "Recall: 74.71%\n",
      "F-measure: 74.74%\n",
      "Runtime: 85.70 seconds\n",
      "Overall Average Accuracy: 79.18%\n",
      "Results have been written to D:\\AIL301m\\time\\Stacking\\SIFT.csv\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths_SIFTandBOW:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data['features'].apply(eval).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "    # Define base models with specific parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=4, weights='distance',metric='euclidean')\n",
    "    ann = MLPClassifier(activation='tanh',alpha=0.05, hidden_layer_sizes=(50,) ,max_iter=1000, random_state=42)\n",
    "    svm = SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=1200, max_features=18,criterion='entropy',max_depth=10, random_state=42)\n",
    "    \n",
    "    # Define meta-learner\n",
    "    meta_learner = LogisticRegression(C=100, solver='liblinear',random_state=42)\n",
    "    \n",
    "    # Create the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('knn', knn), ('ann', ann), ('svm', svm), ('rf', rf)],\n",
    "        final_estimator=meta_learner,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier\n",
    "    start_time = time.time()\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_pred = stacking_classifier.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    runtimes.append(runtime)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Stacking Model (KNN + ANN + SVM + RF):\")\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"Runtime: {runtime:.2f} seconds\")  # Output runtime\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{runtime:.2f} seconds\"\n",
    "    ])\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'D:\\AIL301m\\time\\Stacking\\SIFT.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'Runtime (s)'])\n",
    "    writer.writerows(results)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Average Accuracy: {average_accuracy * 100:.2f}%\") \n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_GIST = [\n",
    "    r'D:\\AIL301m\\Feature extract\\GIST\\Merged_BC-15_GIST_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GIST\\Merged_Huong_thom-1_GIST_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GIST\\Merged_Nep-87_GIST_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GIST\\Merged_Q-5_modify_GIST_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GIST\\Merged_Thien_uu-8_GIST_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\GIST\\Merged_Xi-23_GIST_features.csv'\n",
    "]\n",
    "results = []\n",
    "accuracies = []\n",
    "runtimes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\AIL301m\\Feature extract\\GIST\\Merged_BC-15_GIST_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 78.67%\n",
      "Precision: 78.68%\n",
      "Recall: 78.67%\n",
      "F-measure: 78.67%\n",
      "Runtime: 398.63 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GIST\\Merged_Huong_thom-1_GIST_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 88.32%\n",
      "Precision: 88.33%\n",
      "Recall: 88.32%\n",
      "F-measure: 88.32%\n",
      "Runtime: 389.13 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GIST\\Merged_Nep-87_GIST_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 91.25%\n",
      "Precision: 91.27%\n",
      "Recall: 91.25%\n",
      "F-measure: 91.25%\n",
      "Runtime: 259.84 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GIST\\Merged_Q-5_modify_GIST_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 79.58%\n",
      "Precision: 79.58%\n",
      "Recall: 79.58%\n",
      "F-measure: 79.58%\n",
      "Runtime: 296.80 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GIST\\Merged_Thien_uu-8_GIST_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 94.11%\n",
      "Precision: 94.14%\n",
      "Recall: 94.11%\n",
      "F-measure: 94.11%\n",
      "Runtime: 153.71 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\GIST\\Merged_Xi-23_GIST_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 82.82%\n",
      "Precision: 83.12%\n",
      "Recall: 82.82%\n",
      "F-measure: 82.87%\n",
      "Runtime: 474.68 seconds\n",
      "Overall Average Accuracy: 85.79%\n",
      "Results have been written to D:\\AIL301m\\time\\Stacking\\GIST.csv\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths_GIST:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.apply(lambda row: [float(x) for x in row['GistFeature'].split(',')], axis=1).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "    # Define base models with specific parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=4, weights='distance',metric='euclidean')\n",
    "    ann = MLPClassifier(activation='tanh',alpha=0.05, hidden_layer_sizes=(50,) ,max_iter=1000, random_state=42)\n",
    "    svm = SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=1200, max_features=23,criterion='entropy',max_depth=10, random_state=42)\n",
    "    \n",
    "    # Define meta-learner\n",
    "    meta_learner = LogisticRegression(C=100, solver='liblinear',random_state=42)\n",
    "    \n",
    "    # Create the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('knn', knn), ('ann', ann), ('svm', svm), ('rf', rf)],\n",
    "        final_estimator=meta_learner,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier\n",
    "    start_time = time.time()\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_pred = stacking_classifier.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    runtimes.append(runtime)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Stacking Model (KNN + ANN + SVM + RF):\")\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"Runtime: {runtime:.2f} seconds\")  # Output runtime\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{runtime:.2f} seconds\"\n",
    "    ])\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'D:\\AIL301m\\time\\Stacking\\GIST.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'Runtime (s)'])\n",
    "    writer.writerows(results)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Average Accuracy: {average_accuracy * 100:.2f}%\") \n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_HOG = [\n",
    "    r'D:\\AIL301m\\Feature extract\\HOG\\Merged_BC-15_HOG_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\HOG\\Merged_Huong_thom-1_HOG_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\HOG\\Merged_Nep-87_HOG_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\HOG\\Merged_Q-5_modify_HOG_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\HOG\\Merged_Thien_uu-8_HOG_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\HOG\\Merged_Xi-23_HOG_features.csv'\n",
    "]\n",
    "results = []\n",
    "accuracies = []\n",
    "runtimes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_paths_HOG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfile_paths_HOG\u001b[49m:\n\u001b[0;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      3\u001b[0m     X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHogFeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_paths_HOG' is not defined"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths_HOG:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.apply(lambda row: [float(x) for x in row['HogFeature'].split(',')], axis=1).tolist()\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "    # Define base models with specific parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=4, weights='distance',metric='euclidean')\n",
    "    ann = MLPClassifier(activation='tanh',alpha=0.05, hidden_layer_sizes=(50,) ,max_iter=1000, random_state=42)\n",
    "    svm = SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=1200, max_features=23,criterion='entropy',max_depth=10, random_state=42)\n",
    "    \n",
    "    # Define meta-learner\n",
    "    meta_learner = LogisticRegression(C=100, solver='liblinear',random_state=42)\n",
    "    \n",
    "    # Create the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('knn', knn), ('ann', ann), ('svm', svm), ('rf', rf)],\n",
    "        final_estimator=meta_learner,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier\n",
    "    start_time = time.time()\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_pred = stacking_classifier.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    runtimes.append(runtime)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Stacking Model (KNN + ANN + SVM + RF):\")\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"Runtime: {runtime:.2f} seconds\")  # Output runtime\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{runtime:.2f} seconds\"\n",
    "    ])\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'D:\\AIL301m\\time\\Stacking\\HOG.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'Runtime (s)'])\n",
    "    writer.writerows(results)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Average Accuracy: {average_accuracy * 100:.2f}%\") \n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths_basic = [\n",
    "    r'D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_BC-15_basic_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Huong_thom-1_basic_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Nep-87_basic_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Q-5_modify_basic_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Thien_uu-8_basic_features.csv',\n",
    "    r'D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Xi-23_features.csv'\n",
    "]\n",
    "results = []\n",
    "accuracies = []\n",
    "runtimes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_BC-15_basic_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 91.85%\n",
      "Precision: 91.89%\n",
      "Recall: 91.85%\n",
      "F-measure: 91.84%\n",
      "Runtime: 106.20 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Huong_thom-1_basic_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 94.31%\n",
      "Precision: 94.37%\n",
      "Recall: 94.31%\n",
      "F-measure: 94.31%\n",
      "Runtime: 97.19 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Nep-87_basic_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 97.68%\n",
      "Precision: 97.70%\n",
      "Recall: 97.68%\n",
      "F-measure: 97.68%\n",
      "Runtime: 47.04 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Q-5_modify_basic_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 95.17%\n",
      "Precision: 95.21%\n",
      "Recall: 95.17%\n",
      "F-measure: 95.17%\n",
      "Runtime: 70.51 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Thien_uu-8_basic_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 97.89%\n",
      "Precision: 97.89%\n",
      "Recall: 97.89%\n",
      "F-measure: 97.89%\n",
      "Runtime: 43.00 seconds\n",
      "File: D:\\AIL301m\\Feature extract\\basic\\18_feature\\Merged_Xi-23_features.csv\n",
      "Stacking Model (KNN + ANN + SVM + RF):\n",
      "Accuracy: 95.83%\n",
      "Precision: 95.83%\n",
      "Recall: 95.83%\n",
      "F-measure: 95.83%\n",
      "Runtime: 105.91 seconds\n",
      "Overall Average Accuracy: 95.45%\n",
      "Results have been written to D:\\AIL301m\\time\\Stacking\\basic_18.csv\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths_basic:\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(['filename', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "    # Define base models with specific parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=4, weights='distance',metric='euclidean')\n",
    "    ann = MLPClassifier(activation='tanh',alpha=0.05, hidden_layer_sizes=(50,) ,max_iter=1000, random_state=42)\n",
    "    svm = SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=1200, max_features=5,criterion='entropy',max_depth=10, random_state=42)\n",
    "    \n",
    "    # Define meta-learner\n",
    "    meta_learner = LogisticRegression(C=100, solver='liblinear',random_state=42)\n",
    "    \n",
    "    # Create the stacking classifier\n",
    "    stacking_classifier = StackingClassifier(\n",
    "        estimators=[('knn', knn), ('ann', ann), ('svm', svm), ('rf', rf)],\n",
    "        final_estimator=meta_learner,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "    # Train the stacking classifier\n",
    "    start_time = time.time()\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_pred = stacking_classifier.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    runtimes.append(runtime)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(\"Stacking Model (KNN + ANN + SVM + RF):\")\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F-measure: {f1 * 100:.2f}%\")\n",
    "    print(f\"Runtime: {runtime:.2f} seconds\")  # Output runtime\n",
    "\n",
    "    # Format the results to xx,xx%\n",
    "    results.append([\n",
    "        file_path,\n",
    "        f\"{acc * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{precision * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{recall * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{f1 * 100:.2f}\".replace('.', ',') + '%',\n",
    "        f\"{runtime:.2f} seconds\"\n",
    "    ])\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = r'D:\\AIL301m\\time\\Stacking\\basic_18.csv'\n",
    "\n",
    "# Write the results to a CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File', 'Accuracy', 'Precision', 'Recall', 'F-measure', 'Runtime (s)'])\n",
    "    writer.writerows(results)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Average Accuracy: {average_accuracy * 100:.2f}%\") \n",
    "\n",
    "print(f\"Results have been written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
